library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 10000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
pca.visual.flavour = "technical",
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 10000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
pca.visual.flavour = "technical",
mfw.min = 200, mfw.max = 200,
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 10000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
pca.visual.flavour = "technical",
mfw.min = 200, mfw.max = 200,
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 10000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 10000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 10000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
pca.visual.flavour = "technical",
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 1000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
pca.visual.flavour = "technical",
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 1000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
#      pca.visual.flavour = "technical",
write.png.file = FALSE, gui = FALSE)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
pca.visual.flavour = "loadings",
write.png.file = FALSE, gui = FALSE)
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 1000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
pca.visual.flavour = "loadings",
write.png.file = FALSE, gui = FALSE)
par(mfrow = c(1, 1))
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 1000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
pca.visual.flavour = "loadings",
write.png.file = FALSE, gui = FALSE)
par(mfrow = c(1, 1))
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 10000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
pca.visual.flavour = "loadings",
write.png.file = FALSE, gui = FALSE)
par(mfrow = c(1, 1))
library(stylo)
library(rjson)
raw.corpus <- load.corpus(files = "all", corpus.dir = "/Users/tim/GitHub/frankenstein-v2/pca/pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 5000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "/Users/tim/GitHub/frankenstein-v2/pca/f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
#      pca.visual.flavour = "loadings",
write.png.file = FALSE, gui = FALSE)
par(mfrow = c(1, 1))
library(stylo)
library(rjson)
setwd("/Users/tim/GitHub/frankenstein-v2/pca")
raw.corpus <- load.corpus(files = "all", corpus.dir = "./pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 5000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "./f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
#      pca.visual.flavour = "loadings",
write.png.file = FALSE, gui = FALSE)
par(mfrow = c(1, 1))
library(stylo)
library(rjson)
setwd("/Users/tim/GitHub/frankenstein-v2/pca")
raw.corpus <- load.corpus(files = "all", corpus.dir = "./pca_texts",
encoding = "UTF-8")
tokenized.corpus <- txt.to.words.ext(raw.corpus, language = "English.all",
preserve.case = FALSE)
summary(tokenized.corpus)
sliced.corpus <- make.samples(tokenized.corpus, sampling = "normal.sampling",
sample.size = 5000)
# Temporary list of frequent function words, eventually needs to based on Frankenstein as well
frequent.features <- fromJSON(file = "./f_words.json")
freqs <- make.table.of.frequencies(sliced.corpus, features = frequent.features)
stylo(frequencies = freqs, analysis.type = "PCR",
custom.graph.title = "Lamb vs. the Shelleys",
mfw.min = 200, mfw.max = 200,
pca.visual.flavour = "loadings",
write.png.file = FALSE, gui = FALSE)
par(mfrow = c(1, 1))
library(stylo)
setwd("/Users/tim/GitHub/frankenstein-v2/analysis")
rolling.classify(write.png.file = FALSE,
classification.method = "svm", mfw = 100,
training.set.sampling = "normal.sampling",
slice.size = 5000, slice.overlap = 4500)
library(stylo)
setwd("/Users/tim/GitHub/frankenstein-v2/analysis")
rolling.classify(write.png.file = FALSE,
classification.method = "svm", mfw = 100,
training.set.sampling = "normal.sampling",
slice.size = 1000, slice.overlap = 900)
library(stylo)
setwd("/Users/tim/GitHub/frankenstein-v2/analysis")
rolling.classify(write.png.file = FALSE,
classification.method = "svm", mfw = 100,
training.set.sampling = "normal.sampling",
slice.size = 1000, slice.overlap = 900)
